{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e7cf512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15184\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import pathlib\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "import keras\n",
    "#import keras\n",
    "#from keras import ops\n",
    "\n",
    "#import tensorflow.data as tf_data\n",
    "#from tensorflow_text.tools.wordpiece_vocab import (\n",
    "    #bert_vocab_from_dataset as bert_vocab,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f90ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import tensorflow.strings as tf_strings\n",
    "import tensorflow.data as tf_data\n",
    "from keras.layers import TextVectorization\n",
    "import re\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e7f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a83599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1  # This should be at least 10 for convergence\n",
    "MAX_SEQUENCE_LENGTH = 40\n",
    "VOCAB_SIZE = 50000\n",
    "\n",
    "EMBED_DIM = 256\n",
    "INTERMEDIATE_DIM = 2048\n",
    "NUM_HEADS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fbcd8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.tok.fr.txt', encoding=\"utf8\" ) as f:\n",
    "    fr_lines = f.read().split(\"\\n\")[:-1]\n",
    "f.close()\n",
    "with open('train.tok.fr.txt', encoding=\"utf8\" ) as f:\n",
    "    en_lines = f.read().split(\"\\n\")[:-1]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f46027c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'I N . U s e r . a u t h o r i z e # f u n c t i o n # # #', 'I N . U s e r . l o g o u t # f u n c t i o n # # #', 'u s e r . e m a i l ▁ # r e s . e m a i l A d d r e s s #', 'u s e r . f i r s t N a m e ▁ # ▁ r e s . l a s t N a m e #']\n"
     ]
    }
   ],
   "source": [
    "print(fr_lines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7771e38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'I N . U s e r . a u t h o r i z e # f u n c t i o n # # #', 'I N . U s e r . l o g o u t # f u n c t i o n # # #', 'u s e r . e m a i l ▁ # r e s . e m a i l A d d r e s s #', 'u s e r . f i r s t N a m e ▁ # ▁ r e s . l a s t N a m e #']\n"
     ]
    }
   ],
   "source": [
    "print(en_lines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ff1b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "diction = {'fr': fr_lines, 'en':en_lines}\n",
    "train = pd.DataFrame(diction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66a4c677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  fr  \\\n",
      "0                                                      \n",
      "1  I N . U s e r . a u t h o r i z e # f u n c t ...   \n",
      "2  I N . U s e r . l o g o u t # f u n c t i o n ...   \n",
      "3  u s e r . e m a i l ▁ # r e s . e m a i l A d ...   \n",
      "4  u s e r . f i r s t N a m e ▁ # ▁ r e s . l a ...   \n",
      "\n",
      "                                                  en  \n",
      "0                                                     \n",
      "1  I N . U s e r . a u t h o r i z e # f u n c t ...  \n",
      "2  I N . U s e r . l o g o u t # f u n c t i o n ...  \n",
      "3  u s e r . e m a i l ▁ # r e s . e m a i l A d ...  \n",
      "4  u s e r . f i r s t N a m e ▁ # ▁ r e s . l a ...  \n"
     ]
    }
   ],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f17db5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pairs = []\n",
    "for line in train.index:\n",
    "    text_pairs.append((train['fr'][line],train['en'][line]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9787adad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('# ▁ a b l e ▁ t o ▁ r e t u r n ▁ a ▁ v a l u e ▁ t h a t ▁ h a s ▁ n o t ▁ b e e n ▁ c o n f i g u r e d ▁ h a s ▁ p r o p e r t y ▁ # e x # ▁ t h e ▁ D O M ▁ n o d e ▁ w h i c h ▁ i d', '# ▁ a b l e ▁ t o ▁ r e t u r n ▁ a ▁ v a l u e ▁ t h a t ▁ h a s ▁ n o t ▁ b e e n ▁ c o n f i g u r e d ▁ h a s ▁ p r o p e r t y ▁ # e x # ▁ t h e ▁ D O M ▁ n o d e ▁ w h i c h ▁ i d')\n",
      "('S h o w s ▁ a g g r e g a t e ▁ d e t a i l s ▁ o f ▁ e a c h ▁ e a c h ▁ s e t ▁ o f ▁ i t e r a t i o n s #', 'S h o w s ▁ a g g r e g a t e ▁ d e t a i l s ▁ o f ▁ e a c h ▁ e a c h ▁ s e t ▁ o f ▁ i t e r a t i o n s #')\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7addca2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242306 total pairs\n",
      "205961 training pairs\n",
      "36345 validation pairs\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) -  num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples : ]\n",
    "\n",
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "print(f\"{len(val_pairs)} validation pairs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceebdbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12752 total pairs\n"
     ]
    }
   ],
   "source": [
    "with open('dev.tok.fr.txt', encoding=\"utf8\" ) as f:\n",
    "    fr_lines = f.read().split(\"\\n\")[:-1]\n",
    "f.close()\n",
    "with open('dev.tok.en.txt', encoding=\"utf8\" ) as f:\n",
    "    en_lines = f.read().split(\"\\n\")[:-1]\n",
    "f.close()\n",
    "diction = {'fr': fr_lines, 'en':en_lines}\n",
    "test = pd.DataFrame(diction)\n",
    "test_pairs = []\n",
    "for line in test.index:\n",
    "    test_pairs.append((test['fr'][line],test['en'][line]))\n",
    "    \n",
    "random.shuffle(test_pairs)\n",
    "print(f\"{len(test_pairs)} total pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85219c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_chars = string.punctuation\n",
    "strip_chars = strip_chars.replace(\"#\", \"\")\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf_strings.lower(input_string)\n",
    "    return tf_strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "\n",
    "fr_vectorization = TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    standardize=custom_standardization\n",
    ")\n",
    "\n",
    "en_vectorization = TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    standardize=custom_standardization\n",
    ")\n",
    "\n",
    "train_fr_texts = [pair[0] for pair in train_pairs]\n",
    "train_en_texts = [pair[1] for pair in train_pairs]\n",
    "fr_vectorization.adapt(train_fr_texts)\n",
    "en_vectorization.adapt(train_en_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fbb3e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(fr, en):\n",
    "    fr = fr_vectorization(fr)\n",
    "    en = en_vectorization(en)\n",
    "    return (\n",
    "        {\n",
    "            \"encoder_inputs\": fr,\n",
    "            \"decoder_inputs\": en,\n",
    "        },\n",
    "        en,\n",
    "    )\n",
    "\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    fr_texts, en_texts = zip(*pairs)\n",
    "    fr_texts = list(fr_texts)\n",
    "    en_texts = list(en_texts)\n",
    "    dataset = tf_data.Dataset.from_tensor_slices((fr_texts, en_texts))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.cache().shuffle(2048).prefetch(16)\n",
    "\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)\n",
    "test_ds = make_dataset(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c32290c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"encoder_inputs\"].shape: (64, 40)\n",
      "inputs[\"decoder_inputs\"].shape: (64, 40)\n",
      "targets.shape: (64, 40)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
    "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec7d7351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.ops as ops\n",
    "\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(dense_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
    "        else:\n",
    "            padding_mask = None\n",
    "\n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
    "        )\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "                \"dense_dim\": self.dense_dim,\n",
    "                \"num_heads\": self.num_heads,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=embed_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = ops.shape(inputs)[-1]\n",
    "        positions = ops.arange(0, length, 1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if mask is None:\n",
    "            return None\n",
    "        else:\n",
    "            return ops.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"sequence_length\": self.sequence_length,\n",
    "                \"vocab_size\": self.vocab_size,\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(latent_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
    "            padding_mask = ops.minimum(padding_mask, causal_mask)\n",
    "        else:\n",
    "            padding_mask = None\n",
    "\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
    "        )\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        return self.layernorm_3(out_2 + proj_output)\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = ops.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = ops.arange(sequence_length)[:, None]\n",
    "        j = ops.arange(sequence_length)\n",
    "        mask = ops.cast(i >= j, dtype=\"int32\")\n",
    "        mask = ops.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = ops.concatenate(\n",
    "            [ops.expand_dims(batch_size, -1), ops.convert_to_tensor([1, 1])],\n",
    "            axis=0,\n",
    "        )\n",
    "        return ops.tile(mask, mult)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "                \"latent_dim\": self.latent_dim,\n",
    "                \"num_heads\": self.num_heads,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4552eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\15184\\anaconda3\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:174: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 256\n",
    "latent_dim = 2048\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "x = PositionalEmbedding(MAX_SEQUENCE_LENGTH, VOCAB_SIZE, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
    "x = PositionalEmbedding(MAX_SEQUENCE_LENGTH, VOCAB_SIZE, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
    "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "transformer = keras.Model(\n",
    "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77815089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ positional_embedding          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">12,810,240</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder_inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ transformer_encoder           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ functional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50000</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">30,919,760</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                               │                           │                 │ transformer_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ positional_embedding          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │      \u001b[38;5;34m12,810,240\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder_inputs (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ transformer_encoder           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m3,155,456\u001b[0m │ positional_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ functional_5 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50000\u001b[0m)       │      \u001b[38;5;34m30,919,760\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                               │                           │                 │ transformer_encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,885,456</span> (178.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m46,885,456\u001b[0m (178.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,885,456</span> (178.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m46,885,456\u001b[0m (178.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3219/3219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9541s\u001b[0m 3s/step - accuracy: 0.9944 - loss: 0.3382 - val_accuracy: 1.0000 - val_loss: 4.0021e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x19ef97a3ca0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 1 \n",
    "\n",
    "transformer.summary()\n",
    "transformer.compile(\n",
    "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acb2db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.save_weights(\"transformermodel.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3134aa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 15/200\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 802ms/step - accuracy: 1.0000 - loss: 4.1337e-06"
     ]
    }
   ],
   "source": [
    "#Test accuracy on test data\n",
    "\n",
    "score, acc = transformer.evaluate(test_ds, batch_size=BATCH_SIZE)\n",
    "print('Test accuracy with transformers:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
